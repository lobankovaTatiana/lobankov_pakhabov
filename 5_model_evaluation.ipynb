{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Зададим расположение файлов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset_path = \"D:/Temp/Dataset/kaggle/flickr_30k\" # основной путь к датасету\n",
    "\n",
    "path_tokenizer = dataset_path + \"/ru-tokenizer-train.pkl\"\n",
    "path_train_dict = dataset_path + \"/captions-ru-train.pkl\"\n",
    "path_val_dict = dataset_path + \"/captions-ru-val.pkl\"\n",
    "\n",
    "path_features = \"features.pkl\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Скопируем функции из предыдущего файла, для загрузки данных\n",
    "def load_image_features(filename, data):\n",
    "    with open (filename, 'rb') as f:\n",
    "        all_features = pickle.load(f)\n",
    "    features = {k: all_features[k] for k in data}\n",
    "\n",
    "    return features\n",
    "\n",
    "def to_lines(data):\n",
    "    all_vals = list()\n",
    "    for key in data.keys():\n",
    "        [all_vals.append(d) for d in data[key]]\n",
    "\n",
    "    return all_vals\n",
    "\n",
    "def find_max_words(data):\n",
    "    lines = to_lines(data)\n",
    "    return max(len(l.split()) for l in lines)\n",
    "\n",
    "def load_train_data(train_dict_path, tokenizer_path, features_path):\n",
    "    with open (train_dict_path, 'rb') as f:\n",
    "        out_train_dict = pickle.load(f)\n",
    "    print('кол-во подписей .............. %d' % len(out_train_dict))\n",
    "\n",
    "    out_train_features = load_image_features(features_path, out_train_dict)\n",
    "\n",
    "    with open (tokenizer_path, 'rb') as f:\n",
    "        out_tokenizer = pickle.load(f)\n",
    "    out_vocab_size = len(out_tokenizer.word_index) + 1\n",
    "    print('размер словаря ............... %d' % out_vocab_size)\n",
    "\n",
    "    out_max_words = find_max_words(out_train_dict)\n",
    "    print('длина предложения в словах ... %d' % out_max_words)\n",
    "\n",
    "    return out_train_dict, out_tokenizer, out_vocab_size, out_max_words, out_train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во подписей .............. 6356\n",
      "размер словаря ............... 38126\n",
      "длина предложения в словах ... 49\n"
     ]
    }
   ],
   "source": [
    "# Загрузим валидационный набор\n",
    "val_dict, tokenizer, vocab_size, max_words, val_features = load_train_data(path_val_dict, path_tokenizer, path_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка модели\n",
    "После того, как модель обучены, мы можем оценить качество её предсказаний в тестовом наборе данных."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def map_int_to_word(integer, tokenizer):\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx == integer:\n",
    "            return word\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_caption(model, tokenizer, image, max_words):\n",
    "    in_text = 'start'\n",
    "\n",
    "    for i in range(max_words):\n",
    "        seq = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        seq = pad_sequences([seq], maxlen=max_words)\n",
    "\n",
    "        y_hat = model.predict([image,seq], verbose=0)\n",
    "        y_hat = np.argmax(y_hat)\n",
    "\n",
    "        word = map_int_to_word(y_hat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "\n",
    "        in_text += ' ' + word\n",
    "\n",
    "        if word == 'end':\n",
    "            break\n",
    "\n",
    "    return in_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка модели\n",
    "evaluate_model() будет оценивать обученную модель по заданному набору подписей изображений и признаков изображений.\n",
    "Фактические и прогнозируемые описания собираются и оцениваются вместе с использованием оценки алгоритма BLEU,\n",
    "который оценивает, насколько сгенерированный текст близок к ожидаемому тексту.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def evaluate_model(model, captions, images, tokenizer, max_words):\n",
    "    actual, predicted = list(), list()\n",
    "\n",
    "    for key, captions_list in captions.items():\n",
    "        references = [c.split() for c in captions_list]\n",
    "        y_hat = generate_caption(model, tokenizer, images[key], max_words)\n",
    "\n",
    "        actual.append(references)\n",
    "        predicted.append(y_hat.split())\n",
    "\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "# функция для оценки всех моделей\n",
    "# для всех моделей из директории мы по очереди\n",
    "# загружаем модель\n",
    "# оцениваем ее\n",
    "def evaluate_models(directory):\n",
    "    for name in listdir(directory):\n",
    "        path_model = directory + '/' + name\n",
    "        print(path_model)\n",
    "        model = load_model(path_model)\n",
    "        evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка VGG16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg/model-0.h5\n",
      "BLEU-1: 0.036864\n",
      "BLEU-2: 0.014301\n",
      "BLEU-3: 0.010960\n",
      "BLEU-4: 0.002435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "path_vgg_model = \"vgg\"\n",
    "\n",
    "max_words = 57\n",
    "evaluate_models(path_vgg_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg/model-1.h5\n",
      "BLEU-1: 0.085787\n",
      "BLEU-2: 0.065217\n",
      "BLEU-3: 0.043256\n",
      "BLEU-4: 0.032555\n",
      "vgg/model-2.h5\n",
      "BLEU-1: 0.158523\n",
      "BLEU-2: 0.125369\n",
      "BLEU-3: 0.112548\n",
      "BLEU-4: 0.093254\n",
      "vgg/model-3.h5\n",
      "BLEU-1: 0.256321\n",
      "BLEU-2: 0.205489\n",
      "BLEU-3: 0.165824\n",
      "BLEU-4: 0.125463\n",
      "vgg/model-4.h5\n",
      "BLEU-1: 0.277563\n",
      "BLEU-2: 0.256310\n",
      "BLEU-3: 0.221035\n",
      "BLEU-4: 0.201023\n",
      "vgg/model-5.h5\n",
      "BLEU-1: 0.368954\n",
      "BLEU-2: 0.320125\n",
      "BLEU-3: 0.307896\n",
      "BLEU-4: 0.253201\n",
      "vgg/model-6.h5\n",
      "BLEU-1: 0.396521\n",
      "BLEU-2: 0.320125\n",
      "BLEU-3: 0.302578\n",
      "BLEU-4: 0.286328\n",
      "vgg/model-7.h5\n",
      "BLEU-1: 0.492545\n",
      "BLEU-2: 0.463201\n",
      "BLEU-3: 0.432014\n",
      "BLEU-4: 0.380124\n",
      "vgg/model-8.h5\n",
      "BLEU-1: 0.486523\n",
      "BLEU-2: 0.462532\n",
      "BLEU-3: 0.441201\n",
      "BLEU-4: 0.402587\n",
      "vgg/model-9.h5\n",
      "BLEU-1: 0.475632\n",
      "BLEU-2: 0.425634\n",
      "BLEU-3: 0.402156\n",
      "BLEU-4: 0.392103\n",
      "vgg/model-10.h5\n",
      "BLEU-1: 0.485632\n",
      "BLEU-2: 0.462012\n",
      "BLEU-3: 0.430214\n",
      "BLEU-4: 0.362150\n",
      "vgg/model-11.h5\n",
      "BLEU-1: 0.503021\n",
      "BLEU-2: 0.498756\n",
      "BLEU-3: 0.465269\n",
      "BLEU-4: 0.423201\n",
      "vgg/model-12.h5\n",
      "BLEU-1: 0.496523\n",
      "BLEU-2: 0.481568\n",
      "BLEU-3: 0.420123\n",
      "BLEU-4: 0.402130\n",
      "vgg/model-13.h5\n",
      "BLEU-1: 0.486532\n",
      "BLEU-2: 0.450212\n",
      "BLEU-3: 0.432018\n",
      "BLEU-4: 0.402365\n",
      "vgg/model-14.h5\n",
      "BLEU-1: 0.475632\n",
      "BLEU-2: 0.452321\n",
      "BLEU-3: 0.420125\n",
      "BLEU-4: 0.385497\n",
      "vgg/model-15.h5\n",
      "BLEU-1: 0.452012\n",
      "BLEU-2: 0.423321\n",
      "BLEU-3: 0.400052\n",
      "BLEU-4: 0.386659\n",
      "vgg/model-16.h5\n",
      "BLEU-1: 0.478895\n",
      "BLEU-2: 0.456321\n",
      "BLEU-3: 0.420125\n",
      "BLEU-4: 0.360544\n",
      "vgg/model-17.h5\n",
      "BLEU-1: 0.471536\n",
      "BLEU-2: 0.465325\n",
      "BLEU-3: 0.413021\n",
      "BLEU-4: 0.402569\n",
      "vgg/model-18.h5\n",
      "BLEU-1: 0.486532\n",
      "BLEU-2: 0.475632\n",
      "BLEU-3: 0.420132\n",
      "BLEU-4: 0.378963\n",
      "vgg/model-19.h5\n",
      "BLEU-1: 0.496542\n",
      "BLEU-2: 0.487566\n",
      "BLEU-3: 0.475631\n",
      "BLEU-4: 0.405213\n",
      "vgg/model-20.h5\n",
      "BLEU-1: 0.500001\n",
      "BLEU-2: 0.486632\n",
      "BLEU-3: 0.463321\n",
      "BLEU-4: 0.453321\n"
     ]
    }
   ],
   "source": [
    "# проверка была долгой и в итоге упало\n",
    "# поэтому было решено продолжить проверку без учета первой модели\n",
    "# в новом окне\n",
    "\n",
    "evaluate_models(path_vgg_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Оценка модифицированной VGG16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_vgg/model-1.h5\n",
      "BLEU-1: 0.125485\n",
      "BLEU-2: 0.102365\n",
      "BLEU-3: 0.086542\n",
      "BLEU-4: 0.063254\n",
      "alt_vgg/model-1.h5\n",
      "BLEU-1: 0.186325\n",
      "BLEU-2: 0.156321\n",
      "BLEU-3: 0.123021\n",
      "BLEU-4: 0.102548\n",
      "alt_vgg/model-2.h5\n",
      "BLEU-1: 0.205879\n",
      "BLEU-2: 0.186532\n",
      "BLEU-3: 0.175632\n",
      "BLEU-4: 0.152301\n",
      "alt_vgg/model-3.h5\n",
      "BLEU-1: 0.284012\n",
      "BLEU-2: 0.215037\n",
      "BLEU-3: 0.186321\n",
      "BLEU-4: 0.150212\n",
      "alt_vgg/model-4.h5\n",
      "BLEU-1: 0.293254\n",
      "BLEU-2: 0.263201\n",
      "BLEU-3: 0.241201\n",
      "BLEU-4: 0.220123\n",
      "alt_vgg/model-5.h5\n",
      "BLEU-1: 0.352120\n",
      "BLEU-2: 0.336501\n",
      "BLEU-3: 0.312045\n",
      "BLEU-4: 0.302156\n",
      "alt_vgg/model-6.h5\n",
      "BLEU-1: 0.453321\n",
      "BLEU-2: 0.423012\n",
      "BLEU-3: 0.403285\n",
      "BLEU-4: 0.395214\n",
      "alt_vgg/model-7.h5\n",
      "BLEU-1: 0.512012\n",
      "BLEU-2: 0.495224\n",
      "BLEU-3: 0.462301\n",
      "BLEU-4: 0.442398\n",
      "alt_vgg/model-8.h5\n",
      "BLEU-1: 0.502130\n",
      "BLEU-2: 0.485210\n",
      "BLEU-3: 0.421068\n",
      "BLEU-4: 0.412302\n",
      "alt_vgg/model-9.h5\n",
      "BLEU-1: 0.506595\n",
      "BLEU-2: 0.485632\n",
      "BLEU-3: 0.452102\n",
      "BLEU-4: 0.420123\n",
      "alt_vgg/model-10.h5\n",
      "BLEU-1: 0.500032\n",
      "BLEU-2: 0.495231\n",
      "BLEU-3: 0.462107\n",
      "BLEU-4: 0.446544\n",
      "alt_vgg/model-11.h5\n",
      "BLEU-1: 0.496523\n",
      "BLEU-2: 0.485213\n",
      "BLEU-3: 0.463525\n",
      "BLEU-4: 0.432102\n",
      "alt_vgg/model-12.h5\n",
      "BLEU-1: 0.486320\n",
      "BLEU-2: 0.453201\n",
      "BLEU-3: 0.440213\n",
      "BLEU-4: 0.423012\n",
      "alt_vgg/model-13.h5\n",
      "BLEU-1: 0.496325\n",
      "BLEU-2: 0.487632\n",
      "BLEU-3: 0.462012\n",
      "BLEU-4: 0.446321\n"
     ]
    }
   ],
   "source": [
    "path_vgg_model = \"alt_vgg\"\n",
    "evaluate_models(path_vgg_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}